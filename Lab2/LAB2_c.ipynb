{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1Thfmea0N68"
      },
      "outputs": [],
      "source": [
        "# Import các thư viện cần thiết\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_iris_data():\n",
        "    # Load bộ dữ liệu Iris\n",
        "    iris = load_iris()\n",
        "\n",
        "    # Chuyển đổi dữ liệu thành DataFrame\n",
        "    df = pd.DataFrame(data=np.c_[iris['data'], iris['target']],\n",
        "                     columns=iris['feature_names'] + ['target'])\n",
        "\n",
        "    return df, iris['feature_names']"
      ],
      "metadata": {
        "id": "UFqxtMQ71rI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_multivariate_data(df, target_index=0, scale=True):\n",
        "  \"\"\"\n",
        "    Chuẩn bị dữ liệu cho mô hình hồi quy đa biến\n",
        "\n",
        "    Tại sao cần chuẩn hóa dữ liệu (StandardScaler)?\n",
        "\n",
        "    1. Đồng nhất hóa phạm vi giá trị:\n",
        "       - Các đặc trưng có thể có các đơn vị và phạm vi giá trị khác nhau\n",
        "       - Ví dụ: sepal length (4.3-7.9 cm) vs sepal width (2.0-4.4 cm)\n",
        "       - Chuẩn hóa giúp đưa tất cả về cùng phạm vi, thường là mean=0 và std=1\n",
        "\n",
        "    2. Cải thiện quá trình tối ưu với Gradient Descent:\n",
        "       Gradient Descent là gì?\n",
        "       - Là thuật toán tối ưu để tìm giá trị nhỏ nhất (minimum) của hàm mất mát (loss function)\n",
        "       - Hoạt động bằng cách lặp đi lặp lại các bước:\n",
        "         a) Tính gradient (đạo hàm) của hàm mất mát\n",
        "         b) Di chuyển theo hướng ngược với gradient để giảm giá trị hàm mất mát\n",
        "         c) Kích thước bước di chuyển được điều chỉnh bởi learning rate\n",
        "\n",
        "       Tại sao chuẩn hóa giúp Gradient Descent?\n",
        "       - Khi các đặc trưng có phạm vi khác nhau:\n",
        "         + Đặc trưng có giá trị lớn tạo gradient lớn\n",
        "         + Đặc trưng có giá trị nhỏ tạo gradient nhỏ\n",
        "         + Dẫn đến quá trình học không đồng đều\n",
        "\n",
        "       - Sau khi chuẩn hóa:\n",
        "         + Tất cả đặc trưng có cùng phạm vi\n",
        "         + Gradient của các đặc trưng có độ lớn tương đương\n",
        "         + Quá trình học diễn ra đồng đều và hiệu quả hơn\n",
        "         + Tốc độ hội tụ nhanh hơn\n",
        "\n",
        "       Ví dụ với hồi quy tuyến tính:\n",
        "       - Hàm mất mát: MSE = 1/n * Σ(y_pred - y_true)²\n",
        "       - Gradient của MSE với respect to w: ∂MSE/∂w = 2/n * Σ(y_pred - y_true) * x\n",
        "       - Nếu x có giá trị lớn → gradient lớn → bước cập nhật lớn\n",
        "       - Nếu x có giá trị nhỏ → gradient nhỏ → bước cập nhật nhỏ\n",
        "       → Chuẩn hóa giúp cân bằng độ lớn của các bước cập nhật\n",
        "\n",
        "    3. Giúp so sánh hệ số một cách công bằng:\n",
        "       - Khi các đặc trưng đã chuẩn hóa, độ lớn của hệ số phản ánh\n",
        "         trực tiếp tầm quan trọng của đặc trưng đó\n",
        "       - Không bị ảnh hưởng bởi đơn vị đo\n",
        "\n",
        "    Params:\n",
        "        df (DataFrame): DataFrame chứa dữ liệu\n",
        "        target_index (int): Chỉ số của đặc trưng đầu ra (0-3)\n",
        "        scale (bool): Có thực hiện chuẩn hóa dữ liệu hay không\n",
        "\n",
        "    Returns:\n",
        "        tuple: (X_train, X_test, y_train, y_test) đã được xử lý\n",
        "    \"\"\"\n",
        "\n",
        "  # Tách features (X) và target (y)\n",
        "  # Chọn tất cả các cột làm đặc trưng, trừ cột target\n",
        "  features = df.iloc[:, [i for i in range(4) if i != target_index]]\n",
        "\n",
        "  # In thông tin về phạm vi giá trị của các đặc trưng trước khi chuẩn hóa\n",
        "  print(\"\\nPhạm vi giá trị của các đặc trưng trước khi chuẩn hóa:\")\n",
        "  for column in features.columns:\n",
        "      print(f\"{column}:\")\n",
        "      print(f\"  - Min: {features[column].min():.2f}\")\n",
        "      print(f\"  - Max: {features[column].max():.2f}\")\n",
        "      print(f\"  - Mean: {features[column].mean():.2f}\")\n",
        "      print(f\"  - Std: {features[column].std():.2f}\")\n",
        "\n",
        "  # Chọn biến mục tiêu (y)\n",
        "  target = df.iloc[:, target_index]\n",
        "\n",
        "  # Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
        "  X_train, X_test, y_train, y_test = train_test_split(\n",
        "      features, target, test_size=0.2, random_state=42\n",
        "  )\n",
        "  # Chuẩn hóa dữ liệu nếu được yêu cầu\n",
        "  if scale:\n",
        "      # StandardScaler thực hiện chuẩn hóa theo công thức:\n",
        "      # z = (x - μ) / σ\n",
        "      # trong đó:\n",
        "      # - x là giá trị gốc\n",
        "      # - μ là giá trị trung bình\n",
        "      # - σ là độ lệch chuẩn\n",
        "      # Kết quả: các đặc trưng sẽ có mean=0 và std=1\n",
        "      scaler = StandardScaler()\n",
        "\n",
        "      # Fit scaler trên tập train và transform cả train và test\n",
        "      # Quan trọng: chỉ fit trên tập train để tránh data leakage\n",
        "      X_train = scaler.fit_transform(X_train)\n",
        "      X_test = scaler.transform(X_test)\n",
        "\n",
        "      # Chuyển về DataFrame để giữ tên cột và in thông tin\n",
        "      X_train = pd.DataFrame(X_train, columns=features.columns)\n",
        "      X_test = pd.DataFrame(X_test, columns=features.columns)\n",
        "\n",
        "      print(\"\\nPhạm vi giá trị sau khi chuẩn hóa (tập train):\")\n",
        "      for column in X_train.columns:\n",
        "          print(f\"{column}:\")\n",
        "          print(f\"  - Min: {X_train[column].min():.2f}\")\n",
        "          print(f\"  - Max: {X_train[column].max():.2f}\")\n",
        "          print(f\"  - Mean: {X_train[column].mean():.2f}\")\n",
        "          print(f\"  - Std: {X_train[column].std():.2f}\")\n",
        "\n",
        "      # Visualization của phân phối trước và sau khi chuẩn hóa\n",
        "      plt.figure(figsize=(15, 5))\n",
        "\n",
        "      # Trước khi chuẩn hóa\n",
        "      plt.subplot(1, 2, 1)\n",
        "      features.boxplot()\n",
        "      plt.title('Phân phối trước khi chuẩn hóa')\n",
        "      plt.xticks(rotation=45)\n",
        "\n",
        "      # Sau khi chuẩn hóa\n",
        "      plt.subplot(1, 2, 2)\n",
        "      X_train.boxplot()\n",
        "      plt.title('Phân phối sau khi chuẩn hóa')\n",
        "      plt.xticks(rotation=45)\n",
        "\n",
        "      plt.tight_layout()\n",
        "      plt.show()\n",
        "\n",
        "  return X_train, X_test, y_train, y_test\n"
      ],
      "metadata": {
        "id": "LvqAS6Zb2NoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_multivariate_model(X_train, X_test, y_train, y_test, feature_names, target_name):\n",
        "    # Khởi tạo và huấn luyện mô hình\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Dự đoán\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    # Tính các metrics\n",
        "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "    train_r2 = r2_score(y_train, y_train_pred)\n",
        "    test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "    # In kết quả\n",
        "    print(f\"\\nKết quả hồi quy đa biến cho {target_name}\")\n",
        "    print(\"\\nHệ số hồi quy:\")\n",
        "    for name, coef in zip(feature_names, model.coef_):\n",
        "        print(f\"{name}: {coef:.4f}\")\n",
        "    print(f\"Hệ số tự do (w0): {model.intercept_:.4f}\")\n",
        "\n",
        "    print(f\"\\nMetrics đánh giá:\")\n",
        "    print(f\"Train MSE: {train_mse:.4f}\")\n",
        "    print(f\"Test MSE: {test_mse:.4f}\")\n",
        "    print(f\"Train R2 Score: {train_r2:.4f}\")\n",
        "    print(f\"Test R2 Score: {test_r2:.4f}\")\n",
        "\n",
        "    # Vẽ đồ thị so sánh giá trị thực tế và dự đoán\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Tập huấn luyện\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.scatter(y_train, y_train_pred, color='blue')\n",
        "    plt.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--', lw=2)\n",
        "    plt.xlabel('Giá trị thực tế')\n",
        "    plt.ylabel('Giá trị dự đoán')\n",
        "    plt.title('Tập huấn luyện')\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Tập kiểm tra\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.scatter(y_test, y_test_pred, color='blue')\n",
        "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
        "    plt.xlabel('Giá trị thực tế')\n",
        "    plt.ylabel('Giá trị dự đoán')\n",
        "    plt.title('Tập kiểm tra')\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Phân tích tầm quan trọng của các đặc trưng\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'Feature': feature_names,\n",
        "        'Absolute Coefficient': np.abs(model.coef_)\n",
        "    })\n",
        "    feature_importance = feature_importance.sort_values('Absolute Coefficient', ascending=False)\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.bar(feature_importance['Feature'], feature_importance['Absolute Coefficient'])\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.xlabel('Đặc trưng')\n",
        "    plt.ylabel('Độ lớn hệ số hồi quy')\n",
        "    plt.title('Tầm quan trọng của các đặc trưng')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "Ep06uG8l4JtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dữ liệu\n",
        "df, feature_names = load_iris_data()\n",
        "\n",
        "# Chọn một đặc trưng làm target (ví dụ: sepal length)\n",
        "target_index = 0\n",
        "target_name = feature_names[target_index]\n",
        "\n",
        "# Chuẩn bị dữ liệu\n",
        "X_train, X_test, y_train, y_test = prepare_multivariate_data(\n",
        "    df, target_index=target_index, scale=True\n",
        ")\n",
        "\n",
        "# Lấy tên của các đặc trưng đầu vào\n",
        "input_features = [name for i, name in enumerate(feature_names) if i != target_index]\n",
        "\n",
        "# Huấn luyện và đánh giá mô hình\n",
        "model = train_multivariate_model(\n",
        "    X_train, X_test, y_train, y_test,\n",
        "    input_features, target_name\n",
        ")\n",
        "\n",
        "# Demo dự đoán\n",
        "print(\"\\nDemo dự đoán:\")\n",
        "sample_input = X_test.iloc[0]\n",
        "print(\"Đầu vào:\", dict(sample_input))\n",
        "prediction = model.predict([sample_input])[0]\n",
        "print(f\"Dự đoán {target_name}: {prediction:.2f}\")"
      ],
      "metadata": {
        "id": "IrNlAaD-1tw_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}